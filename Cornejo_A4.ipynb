{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizbiz0510/CORNEJO_A4/blob/main/Cornejo_A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-03-20T01:48:22.173359Z",
          "iopub.execute_input": "2023-03-20T01:48:22.173798Z",
          "iopub.status.idle": "2023-03-20T01:48:22.189682Z",
          "shell.execute_reply.started": "2023-03-20T01:48:22.173705Z",
          "shell.execute_reply": "2023-03-20T01:48:22.188784Z"
        },
        "trusted": true,
        "id": "kCR_pJ3VUlKD"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import string"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T01:48:22.191173Z",
          "iopub.execute_input": "2023-03-20T01:48:22.191552Z",
          "iopub.status.idle": "2023-03-20T01:48:28.275743Z",
          "shell.execute_reply.started": "2023-03-20T01:48:22.191520Z",
          "shell.execute_reply": "2023-03-20T01:48:28.274762Z"
        },
        "trusted": true,
        "id": "SQsJlg0XUlKG"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"The-Alchemist-PDF.txt\") as f:\n",
        "    str_txt = f.read()\n",
        "    #print(str_txt)\n",
        "data=str_txt[319:]\n",
        "#data=str_txt[1699900:]\n",
        "#print(data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T01:48:28.277510Z",
          "iopub.execute_input": "2023-03-20T01:48:28.277801Z",
          "iopub.status.idle": "2023-03-20T01:48:28.290484Z",
          "shell.execute_reply.started": "2023-03-20T01:48:28.277773Z",
          "shell.execute_reply": "2023-03-20T01:48:28.289532Z"
        },
        "trusted": true,
        "id": "WhcSyib8UlKH"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(doc):\n",
        "    tokens=doc.split()\n",
        "    table=str.maketrans('','',string.punctuation)\n",
        "    tokens=[w.translate(table) for w in tokens]\n",
        "    tokens=[word for word in tokens if word.isalpha()]\n",
        "    tokens=[word.lower() for word in tokens]\n",
        "    return tokens\n",
        "tokens=clean_text(data)\n",
        "print(tokens[:50])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T01:48:28.292431Z",
          "iopub.execute_input": "2023-03-20T01:48:28.292734Z",
          "iopub.status.idle": "2023-03-20T01:48:28.339640Z",
          "shell.execute_reply.started": "2023-03-20T01:48:28.292706Z",
          "shell.execute_reply": "2023-03-20T01:48:28.338568Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YoaGFNyUlKH",
        "outputId": "857de8b6-6611-4951-b39e-cd3da7d1a314"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'boys', 'name', 'was', 'santiago', 'dusk', 'was', 'falling', 'as', 'the', 'boy', 'arrived', 'with', 'his', 'herd', 'at', 'an', 'abandoned', 'church', 'the', 'roof', 'had', 'fallen', 'in', 'long', 'ago', 'and', 'an', 'enormous', 'sycamore', 'had', 'grown', 'on', 'the', 'spot', 'where', 'the', 'sacristy', 'had', 'once', 'stood', 'he', 'decided', 'to', 'spend', 'the', 'night', 'there', 'he', 'saw']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(len(tokens))\n",
        "\n",
        "print(len(set(tokens)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T01:48:28.341068Z",
          "iopub.execute_input": "2023-03-20T01:48:28.341520Z",
          "iopub.status.idle": "2023-03-20T01:48:28.349683Z",
          "shell.execute_reply.started": "2023-03-20T01:48:28.341486Z",
          "shell.execute_reply": "2023-03-20T01:48:28.348665Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAcxPcUIUlKI",
        "outputId": "a8e3be5e-1824-45f1-835b-7a6396f92a73"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38484\n",
            "3286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "length = 60+1\n",
        "lines=[]\n",
        "for i in range(length,len(tokens)):\n",
        "    seq = tokens[i-length:i]\n",
        "    line= ' '.join(seq)\n",
        "    lines.append(line)\n",
        "n = int(len(lines)*0.9)\n",
        "testset = lines[n:]\n",
        "lines = lines[:n]\n",
        "print(len(lines), len(testset))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T01:48:28.351378Z",
          "iopub.execute_input": "2023-03-20T01:48:28.351796Z",
          "iopub.status.idle": "2023-03-20T01:48:28.437490Z",
          "shell.execute_reply.started": "2023-03-20T01:48:28.351752Z",
          "shell.execute_reply": "2023-03-20T01:48:28.436433Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8FR03VrUlKJ",
        "outputId": "e8f5e9e6-b90d-45bd-a055-83ac3492dab2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34580 3843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer as tk\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T01:48:28.459215Z",
          "iopub.execute_input": "2023-03-20T01:48:28.459643Z",
          "iopub.status.idle": "2023-03-20T01:48:28.469584Z",
          "shell.execute_reply.started": "2023-03-20T01:48:28.459604Z",
          "shell.execute_reply": "2023-03-20T01:48:28.468613Z"
        },
        "trusted": true,
        "id": "o0rh6d8UUlKK"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#converitng the text to integer for model injestion\n",
        "tokenizer=tk()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences=tokenizer.texts_to_sequences(lines)\n",
        " \n",
        "sequences=np.array(sequences)\n",
        "x,y=sequences[:,:-1],sequences[:,-1]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T01:48:28.470799Z",
          "iopub.execute_input": "2023-03-20T01:48:28.471093Z",
          "iopub.status.idle": "2023-03-20T01:48:32.190218Z",
          "shell.execute_reply.started": "2023-03-20T01:48:28.471065Z",
          "shell.execute_reply": "2023-03-20T01:48:32.189400Z"
        },
        "trusted": true,
        "id": "1O-icalVUlKK"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T01:48:32.191263Z",
          "iopub.execute_input": "2023-03-20T01:48:32.191527Z",
          "iopub.status.idle": "2023-03-20T01:48:32.202311Z",
          "shell.execute_reply.started": "2023-03-20T01:48:32.191500Z",
          "shell.execute_reply": "2023-03-20T01:48:32.201298Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKebBF5qUlKL",
        "outputId": "eec3c606-41c3-4c39-a4e9-9c90b4805785"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,  180,  391,    8, 1224, 1697,    8, 3095,   22,    1,   11,\n",
              "        616,   19,   12, 3094,   21,   62, 1695,  955,    1, 1694,    9,\n",
              "        689,   10,  267,  421,    3,   62,  806, 1691,    9, 1690,   33,\n",
              "          1, 3090,   91,    1, 3089,    9,  215,  615,    4,  204,    2,\n",
              "        498,    1,  157,   31,    4,  150,    2,   13,    7,   40,    1,\n",
              "         57,  496,  135,    1, 1222])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T01:48:32.205610Z",
          "iopub.execute_input": "2023-03-20T01:48:32.205883Z",
          "iopub.status.idle": "2023-03-20T01:48:32.211887Z",
          "shell.execute_reply.started": "2023-03-20T01:48:32.205856Z",
          "shell.execute_reply": "2023-03-20T01:48:32.210859Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMdSNFpdUlKL",
        "outputId": "b43aeb71-d11c-4eff-98ff-b901d51610c9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1698"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index\n",
        "print(len(tokenizer.word_index))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T01:48:32.213153Z",
          "iopub.execute_input": "2023-03-20T01:48:32.213443Z",
          "iopub.status.idle": "2023-03-20T01:48:32.223037Z",
          "shell.execute_reply.started": "2023-03-20T01:48:32.213416Z",
          "shell.execute_reply": "2023-03-20T01:48:32.221662Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmz23pHSUlKM",
        "outputId": "6ae812a4-903c-4cda-95aa-d499fcccaa27"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=len(tokenizer.word_index)+1\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T01:48:32.224162Z",
          "iopub.execute_input": "2023-03-20T01:48:32.224449Z",
          "iopub.status.idle": "2023-03-20T01:48:32.234141Z",
          "shell.execute_reply.started": "2023-03-20T01:48:32.224422Z",
          "shell.execute_reply": "2023-03-20T01:48:32.233490Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8pSrBZzUlKM",
        "outputId": "32b6e041-0bbc-4267-f1f6-3550f07facc2"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=to_categorical(y,num_classes=vocab_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T01:48:32.235216Z",
          "iopub.execute_input": "2023-03-20T01:48:32.235515Z",
          "iopub.status.idle": "2023-03-20T01:48:32.358239Z",
          "shell.execute_reply.started": "2023-03-20T01:48:32.235487Z",
          "shell.execute_reply": "2023-03-20T01:48:32.357093Z"
        },
        "trusted": true,
        "id": "_5DVKNbYUlKM"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length=x.shape[1]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T01:48:32.359449Z",
          "iopub.execute_input": "2023-03-20T01:48:32.359754Z",
          "iopub.status.idle": "2023-03-20T01:48:32.363924Z",
          "shell.execute_reply.started": "2023-03-20T01:48:32.359725Z",
          "shell.execute_reply": "2023-03-20T01:48:32.362933Z"
        },
        "trusted": true,
        "id": "krXHfqzWUlKN"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building LSTM Model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T01:48:32.365968Z",
          "iopub.execute_input": "2023-03-20T01:48:32.366378Z",
          "iopub.status.idle": "2023-03-20T01:48:32.376734Z",
          "shell.execute_reply.started": "2023-03-20T01:48:32.366346Z",
          "shell.execute_reply": "2023-03-20T01:48:32.375898Z"
        },
        "trusted": true,
        "id": "elUKnn8qUlKN"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(vocab_size,60,input_length=seq_length))\n",
        "model.add(LSTM(100,return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dense(vocab_size,activation='softmax'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T01:48:32.377899Z",
          "iopub.execute_input": "2023-03-20T01:48:32.378177Z",
          "iopub.status.idle": "2023-03-20T01:48:33.004351Z",
          "shell.execute_reply.started": "2023-03-20T01:48:32.378150Z",
          "shell.execute_reply": "2023-03-20T01:48:33.003447Z"
        },
        "trusted": true,
        "id": "pguv0mc7UlKN"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T01:48:33.005479Z",
          "iopub.execute_input": "2023-03-20T01:48:33.005798Z",
          "iopub.status.idle": "2023-03-20T01:48:33.015941Z",
          "shell.execute_reply.started": "2023-03-20T01:48:33.005769Z",
          "shell.execute_reply": "2023-03-20T01:48:33.014765Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMlFSXbZUlKN",
        "outputId": "d61f9dac-56e7-411a-fe3b-50d767283378"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 60, 60)            185760    \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 60, 100)           64400     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3096)              312696    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 653,356\n",
            "Trainable params: 653,356\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T01:48:33.017182Z",
          "iopub.execute_input": "2023-03-20T01:48:33.017658Z",
          "iopub.status.idle": "2023-03-20T01:48:33.041911Z",
          "shell.execute_reply.started": "2023-03-20T01:48:33.017626Z",
          "shell.execute_reply": "2023-03-20T01:48:33.041059Z"
        },
        "trusted": true,
        "id": "AmYOJLftUlKO"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y,batch_size=100,epochs=100)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T01:48:33.043059Z",
          "iopub.execute_input": "2023-03-20T01:48:33.043356Z",
          "iopub.status.idle": "2023-03-20T03:43:35.309107Z",
          "shell.execute_reply.started": "2023-03-20T01:48:33.043329Z",
          "shell.execute_reply": "2023-03-20T03:43:35.308290Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2rH-ahQUlKO",
        "outputId": "5c89aea8-a8ed-4258-f573-8ffd7ff356fe"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "346/346 [==============================] - 21s 49ms/step - loss: 6.2085 - accuracy: 0.0883\n",
            "Epoch 2/100\n",
            "346/346 [==============================] - 7s 21ms/step - loss: 5.7694 - accuracy: 0.0986\n",
            "Epoch 3/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 5.5133 - accuracy: 0.1109\n",
            "Epoch 4/100\n",
            "346/346 [==============================] - 5s 15ms/step - loss: 5.3281 - accuracy: 0.1305\n",
            "Epoch 5/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 5.1929 - accuracy: 0.1383\n",
            "Epoch 6/100\n",
            "346/346 [==============================] - 4s 13ms/step - loss: 5.0869 - accuracy: 0.1463\n",
            "Epoch 7/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 4.9955 - accuracy: 0.1508\n",
            "Epoch 8/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 4.9106 - accuracy: 0.1584\n",
            "Epoch 9/100\n",
            "346/346 [==============================] - 5s 13ms/step - loss: 4.8334 - accuracy: 0.1615\n",
            "Epoch 10/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 4.7621 - accuracy: 0.1672\n",
            "Epoch 11/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 4.6907 - accuracy: 0.1717\n",
            "Epoch 12/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 4.6232 - accuracy: 0.1745\n",
            "Epoch 13/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 4.5603 - accuracy: 0.1797\n",
            "Epoch 14/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 4.4976 - accuracy: 0.1820\n",
            "Epoch 15/100\n",
            "346/346 [==============================] - 5s 13ms/step - loss: 4.4395 - accuracy: 0.1848\n",
            "Epoch 16/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 4.3876 - accuracy: 0.1876\n",
            "Epoch 17/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 4.3347 - accuracy: 0.1905\n",
            "Epoch 18/100\n",
            "346/346 [==============================] - 5s 14ms/step - loss: 4.2834 - accuracy: 0.1936\n",
            "Epoch 19/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 4.2341 - accuracy: 0.1959\n",
            "Epoch 20/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 4.1833 - accuracy: 0.1996\n",
            "Epoch 21/100\n",
            "346/346 [==============================] - 5s 13ms/step - loss: 4.1395 - accuracy: 0.2015\n",
            "Epoch 22/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 4.1089 - accuracy: 0.2032\n",
            "Epoch 23/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 4.0544 - accuracy: 0.2078\n",
            "Epoch 24/100\n",
            "346/346 [==============================] - 5s 15ms/step - loss: 4.0075 - accuracy: 0.2102\n",
            "Epoch 25/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 3.9647 - accuracy: 0.2126\n",
            "Epoch 26/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 3.9224 - accuracy: 0.2150\n",
            "Epoch 27/100\n",
            "346/346 [==============================] - 5s 13ms/step - loss: 3.8794 - accuracy: 0.2192\n",
            "Epoch 28/100\n",
            "346/346 [==============================] - 4s 10ms/step - loss: 3.8393 - accuracy: 0.2211\n",
            "Epoch 29/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 3.8003 - accuracy: 0.2238\n",
            "Epoch 30/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 3.7631 - accuracy: 0.2267\n",
            "Epoch 31/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 3.7244 - accuracy: 0.2306\n",
            "Epoch 32/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 3.6876 - accuracy: 0.2342\n",
            "Epoch 33/100\n",
            "346/346 [==============================] - 4s 13ms/step - loss: 3.6511 - accuracy: 0.2377\n",
            "Epoch 34/100\n",
            "346/346 [==============================] - 4s 10ms/step - loss: 3.6188 - accuracy: 0.2400\n",
            "Epoch 35/100\n",
            "346/346 [==============================] - 4s 10ms/step - loss: 3.5831 - accuracy: 0.2440\n",
            "Epoch 36/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 3.5526 - accuracy: 0.2474\n",
            "Epoch 37/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 3.5199 - accuracy: 0.2510\n",
            "Epoch 38/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 3.4849 - accuracy: 0.2533\n",
            "Epoch 39/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 3.4565 - accuracy: 0.2573\n",
            "Epoch 40/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 3.4304 - accuracy: 0.2593\n",
            "Epoch 41/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 3.3976 - accuracy: 0.2639\n",
            "Epoch 42/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 3.3764 - accuracy: 0.2674\n",
            "Epoch 43/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 3.3449 - accuracy: 0.2693\n",
            "Epoch 44/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 3.3203 - accuracy: 0.2737\n",
            "Epoch 45/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 3.2955 - accuracy: 0.2768\n",
            "Epoch 46/100\n",
            "346/346 [==============================] - 4s 13ms/step - loss: 3.2693 - accuracy: 0.2815\n",
            "Epoch 47/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 3.2468 - accuracy: 0.2813\n",
            "Epoch 48/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 3.2224 - accuracy: 0.2879\n",
            "Epoch 49/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 3.1973 - accuracy: 0.2916\n",
            "Epoch 50/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 3.1783 - accuracy: 0.2917\n",
            "Epoch 51/100\n",
            "346/346 [==============================] - 4s 10ms/step - loss: 3.1530 - accuracy: 0.2953\n",
            "Epoch 52/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 3.1344 - accuracy: 0.3003\n",
            "Epoch 53/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 3.1096 - accuracy: 0.3034\n",
            "Epoch 54/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 3.0899 - accuracy: 0.3063\n",
            "Epoch 55/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 3.0692 - accuracy: 0.3079\n",
            "Epoch 56/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 3.0487 - accuracy: 0.3141\n",
            "Epoch 57/100\n",
            "346/346 [==============================] - 4s 10ms/step - loss: 3.0270 - accuracy: 0.3135\n",
            "Epoch 58/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 3.0049 - accuracy: 0.3195\n",
            "Epoch 59/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 2.9850 - accuracy: 0.3209\n",
            "Epoch 60/100\n",
            "346/346 [==============================] - 4s 10ms/step - loss: 2.9675 - accuracy: 0.3247\n",
            "Epoch 61/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.9468 - accuracy: 0.3271\n",
            "Epoch 62/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 2.9272 - accuracy: 0.3296\n",
            "Epoch 63/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.9095 - accuracy: 0.3325\n",
            "Epoch 64/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.8866 - accuracy: 0.3346\n",
            "Epoch 65/100\n",
            "346/346 [==============================] - 4s 13ms/step - loss: 2.8660 - accuracy: 0.3403\n",
            "Epoch 66/100\n",
            "346/346 [==============================] - 4s 10ms/step - loss: 2.8529 - accuracy: 0.3434\n",
            "Epoch 67/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.8316 - accuracy: 0.3451\n",
            "Epoch 68/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 2.8145 - accuracy: 0.3476\n",
            "Epoch 69/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.7958 - accuracy: 0.3535\n",
            "Epoch 70/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.7771 - accuracy: 0.3552\n",
            "Epoch 71/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 2.7605 - accuracy: 0.3587\n",
            "Epoch 72/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.7440 - accuracy: 0.3599\n",
            "Epoch 73/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.7257 - accuracy: 0.3644\n",
            "Epoch 74/100\n",
            "346/346 [==============================] - 4s 13ms/step - loss: 2.7067 - accuracy: 0.3688\n",
            "Epoch 75/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.6894 - accuracy: 0.3701\n",
            "Epoch 76/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.6728 - accuracy: 0.3722\n",
            "Epoch 77/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 2.6512 - accuracy: 0.3772\n",
            "Epoch 78/100\n",
            "346/346 [==============================] - 4s 10ms/step - loss: 2.6405 - accuracy: 0.3787\n",
            "Epoch 79/100\n",
            "346/346 [==============================] - 4s 10ms/step - loss: 2.6200 - accuracy: 0.3811\n",
            "Epoch 80/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 2.6032 - accuracy: 0.3855\n",
            "Epoch 81/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.5901 - accuracy: 0.3873\n",
            "Epoch 82/100\n",
            "346/346 [==============================] - 4s 10ms/step - loss: 2.5649 - accuracy: 0.3952\n",
            "Epoch 83/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 2.5540 - accuracy: 0.3940\n",
            "Epoch 84/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.5363 - accuracy: 0.3966\n",
            "Epoch 85/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.5256 - accuracy: 0.4011\n",
            "Epoch 86/100\n",
            "346/346 [==============================] - 4s 10ms/step - loss: 2.5057 - accuracy: 0.4029\n",
            "Epoch 87/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 2.4877 - accuracy: 0.4093\n",
            "Epoch 88/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.4733 - accuracy: 0.4121\n",
            "Epoch 89/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.4547 - accuracy: 0.4144\n",
            "Epoch 90/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 2.4411 - accuracy: 0.4156\n",
            "Epoch 91/100\n",
            "346/346 [==============================] - 4s 10ms/step - loss: 2.4262 - accuracy: 0.4191\n",
            "Epoch 92/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.4103 - accuracy: 0.4230\n",
            "Epoch 93/100\n",
            "346/346 [==============================] - 4s 12ms/step - loss: 2.3955 - accuracy: 0.4239\n",
            "Epoch 94/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.3805 - accuracy: 0.4283\n",
            "Epoch 95/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.3677 - accuracy: 0.4303\n",
            "Epoch 96/100\n",
            "346/346 [==============================] - 4s 13ms/step - loss: 2.3493 - accuracy: 0.4356\n",
            "Epoch 97/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.3318 - accuracy: 0.4368\n",
            "Epoch 98/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.3157 - accuracy: 0.4419\n",
            "Epoch 99/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.3054 - accuracy: 0.4404\n",
            "Epoch 100/100\n",
            "346/346 [==============================] - 4s 11ms/step - loss: 2.2889 - accuracy: 0.4464\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe9e5cca490>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lets take a random line  \n",
        "seed_text=lines[12343]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T03:44:14.352155Z",
          "iopub.execute_input": "2023-03-20T03:44:14.352554Z",
          "iopub.status.idle": "2023-03-20T03:44:14.356885Z",
          "shell.execute_reply.started": "2023-03-20T03:44:14.352524Z",
          "shell.execute_reply": "2023-03-20T03:44:14.355654Z"
        },
        "trusted": true,
        "id": "3acZrWcvUlKP"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\"\"\"\n",
        "generate_text_seq() generates n_words number of words after the given seed_text. We are going to pre-process the seed_text before \n",
        "predicting. We are going to encode the seed_text using the same encoding used for encoding the training data. Then we are going to\n",
        "convert the seed_textto 50 words by using pad_sequences(). Now we will predict using model.predict_classes(). After that we will search\n",
        "the word in tokenizer using the index in y_predict\n",
        "\"\"\"\n",
        "def generate_text_seq(model, tokenizer, text_seq_length, seed_text, n_words):\n",
        "  text = []\n",
        "\n",
        "  for _ in range(n_words):\n",
        "    encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen = text_seq_length, truncating='pre')\n",
        "\n",
        "    temp = model.predict(encoded, verbose=0)\n",
        "    #y_predict = model.predict_classes(encoded)\n",
        "    y_predict = np.argmax(temp, axis=-1)\n",
        "\n",
        "    predicted_word = ''\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == y_predict:\n",
        "        predicted_word = word\n",
        "        break\n",
        "    seed_text = seed_text + ' ' + predicted_word\n",
        "    text.append(predicted_word)\n",
        "  return ' '.join(text) + '\\n'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T03:45:59.949319Z",
          "iopub.execute_input": "2023-03-20T03:45:59.949697Z",
          "iopub.status.idle": "2023-03-20T03:45:59.957082Z",
          "shell.execute_reply.started": "2023-03-20T03:45:59.949666Z",
          "shell.execute_reply": "2023-03-20T03:45:59.955949Z"
        },
        "trusted": true,
        "id": "hkeGW3DoUlKP"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now lets predict 5 examples for the seed word\n",
        "\n",
        "\n",
        "print('Example 1:')\n",
        "seed_text = lines[np.random.randint(0, len(lines)-1)]\n",
        "print('Seed text: ', seed_text, '\\n')\n",
        "print(\"AI generated: \", generate_text_seq(model, tokenizer, seq_length, seed_text, 100))\n",
        "\n",
        "print('Example 2:')\n",
        "seed_text = lines[np.random.randint(0, len(lines)-1)]\n",
        "print('Seed text: ', seed_text, '\\n')\n",
        "print(\"AI generated: \", generate_text_seq(model, tokenizer, seq_length, seed_text, 100))\n",
        "\n",
        "print('Example 3:')\n",
        "seed_text = lines[np.random.randint(0, len(lines)-1)]\n",
        "print('Seed text: ', seed_text, '\\n')\n",
        "print(\"AI generated: \", generate_text_seq(model, tokenizer, seq_length, seed_text, 100))\n",
        "\n",
        "print('Example 4:')\n",
        "seed_text = lines[np.random.randint(0, len(lines)-1)]\n",
        "print('Seed text: ', seed_text, '\\n')\n",
        "print(\"AI generated: \", generate_text_seq(model, tokenizer, seq_length, seed_text, 100))\n",
        "\n",
        "print('Example 5:')\n",
        "seed_text = lines[np.random.randint(0, len(lines)-1)]\n",
        "print('Seed text: ', seed_text, '\\n')\n",
        "print(\"AI generated: \", generate_text_seq(model, tokenizer, seq_length, seed_text, 100))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-20T04:12:14.874379Z",
          "iopub.execute_input": "2023-03-20T04:12:14.874795Z",
          "iopub.status.idle": "2023-03-20T04:12:37.964288Z",
          "shell.execute_reply.started": "2023-03-20T04:12:14.874759Z",
          "shell.execute_reply": "2023-03-20T04:12:37.963075Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62dPSg_mUlKP",
        "outputId": "c8fcdc0c-4e58-442a-e1d1-c6f8b61ae93b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1:\n",
            "Seed text:  an enormous sycamore had grown on the spot where the sacristy had once stood he decided to spend the night there he saw to it that all the sheep entered through the ruined gate and then laid some planks across it to prevent the flock from wandering away during the night there were no wolves in the region but once an \n",
            "\n",
            "AI generated:  animal had strayed during the land the boy suspected that the universe needs to read the book he had been working for the pink in the desert the boy was sad and he had worked hard for a year in the desert disobedience means death he had been forced to appear you easier for to the room of the sunrise and says that the boy was tempted to be rude and move to the wind although the vision of the seemingly endless hours between sunrise and dusk and he quickly busy the englishmans eyes lit with him the boy said\n",
            "\n",
            "Example 2:\n",
            "Seed text:  in the hookah and inhaled deeply ive had this shop for thirty years i know good crystal from bad and everything else there is to know about crystal i know its dimensions and how it behaves if we serve tea in crystal the shop is going to expand and then ill have to change my way of life well isnt that \n",
            "\n",
            "AI generated:  they dont know how they not have to fight it will be a part of the clouds the boy said to the boy the boy pointed to the soul of the world and they drifted on the wind although the vision of the seemingly endless hours between sunrise and dusk and he quickly busy the englishmans eyes lit with him the boy said i know that the boy had taken talking into the wind the boy suspected that the universe had taken talking into the wind the boy was tempted to be rude and move to the wind although the\n",
            "\n",
            "Example 3:\n",
            "Seed text:  had never even noticed that there was a hole in his pouch he knelt down to find urim and thummim and put them back in the pouch but as he saw them lying there on the ground another phrase came to his mind learn to recognize omens and follow them the old king had said an omen the boy smiled to \n",
            "\n",
            "AI generated:  himself the old man had said the boy to peoples illnesses he almost knew that the boy had taken talking into the wind the boy suspected that the universe had taken talking into the wind the boy was tempted to be rude and move to the wind although the vision of the seemingly endless hours between sunrise and dusk and he quickly busy the englishmans eyes lit with him the boy said i know that the boy had taken talking into the wind the boy suspected that the universe had taken talking into the wind the boy was tempted to\n",
            "\n",
            "Example 4:\n",
            "Seed text:  owner of that stall how much the sword costs he said to his friend then he realized that he had been distracted for a few moments looking at the sword his heart squeezed as if his chest had suddenly compressed it he was afraid to look around because he knew what he would find he continued to look at the beautiful \n",
            "\n",
            "AI generated:  universe and everyone ago the desert had fallen into silence you do the old man had spoken to mecca the old man had said the boy to peoples illnesses he almost knew that the owner of the bar stood nearby listening attentively to the bakery and he had to choose between urim and thummim in the ground the boy had spoken to heaven with protection an hour is a breastplate of gold including the existence of the guards stood at attention the boy was becoming more and more convinced that the universe needs none during the land he was reading\n",
            "\n",
            "Example 5:\n",
            "Seed text:  the oasis was your own fear that you might never come back at that point the omens will tell you that your treasure is buried forever then sometime during the fourth year the omens will abandon you because youve stopped listening to them the tribal chieftains will see that and youll be dismissed from your position as counselor but by then \n",
            "\n",
            "AI generated:  he had to go back to his meeting and kings and the wind the boy reiterated i know what he had to be aware of himself and lamenting the fact that he had to choose between urim and thummim in the ground the boy had spoken to heaven with protection an hour is a breastplate of gold including the existence of the guards stood at attention the boy was becoming more and more convinced that the universe needs none during the land he was reading the chores to the miners foot the boy was astonished by what he had attended\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = 0,0\n",
        "for i in testset[0:10]:\n",
        "  encoded = tokenizer.texts_to_sequences([i])[0]\n",
        "  encoded = pad_sequences([encoded], maxlen = seq_length, truncating='pre')\n",
        "  temp = model.evaluate(encoded)\n",
        "  loss += temp[0]\n",
        "  acc += temp[1]\n",
        "\n",
        "print(\"loss: \", loss/len(testset))\n",
        "print(\"accuracy: \", acc/len(testset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29a9TA4cP_89",
        "outputId": "532ff7d5-0109-46cf-b19a-56a6370d546e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "loss:  0.0\n",
            "accuracy:  0.0\n"
          ]
        }
      ]
    }
  ]
}